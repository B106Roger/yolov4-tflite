{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from easydict import EasyDict as edict\n",
    "from tqdm import tqdm\n",
    "FLAGS = edict()\n",
    "\n",
    "# FLAGS.weights ='./checkpoints/day_tw_qat_tf23/save_model_final_tflite/'\n",
    "FLAGS.weights ='./checkpoints/day_tw_qat_tf29/save_model_0059_tflite/'\n",
    "FLAGS.output ='./checkpoints/tmp.tflite'\n",
    "FLAGS.input_size =608\n",
    "FLAGS.quantize_mode ='float32'\n",
    "FLAGS.dataset =\"datasets/data_selection_mix/anno/val_3cls.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "  len_img=50\n",
    "  fimage = open(FLAGS.dataset).readlines()\n",
    "  fimage = [line.split()[0] for line in fimage]\n",
    "  np.random.seed(0)\n",
    "  np.random.shuffle(fimage)\n",
    "  with tqdm(total=len_img, ncols=200) as pbar:\n",
    "    for input_value in range(len_img):\n",
    "      if os.path.exists(fimage[input_value]):\n",
    "        original_image=cv2.imread(fimage[input_value])\n",
    "        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        # Processing V1\n",
    "        # image_data = utils.image_preprocess(np.copy(original_image), [FLAGS.input_size, FLAGS.input_size])\n",
    "        #####################################################################################################\n",
    "        # Processing V2\n",
    "        image_data = cv2.resize(np.copy(original_image), (FLAGS.input_size, FLAGS.input_size))\n",
    "        image_data = image_data / 255.0\n",
    "        #####################################################################################################\n",
    "        img_in = image_data[np.newaxis, ...].astype(np.float32)\n",
    "        pbar.set_postfix({\n",
    "          'image': fimage[input_value]\n",
    "        })\n",
    "        pbar.update(1)\n",
    "        yield [img_in]\n",
    "      else:\n",
    "        pbar.set_postfix({\n",
    "          'image': ''\n",
    "        })\n",
    "        pbar.update(1)\n",
    "\n",
    "def add_statistic(filename):\n",
    "  layer_stats = pd.read_csv(filename)\n",
    "  print(layer_stats.head())\n",
    "  layer_stats['range'] = 255.0 * layer_stats['scale']\n",
    "  layer_stats['rmse/scale'] = layer_stats.apply(\n",
    "      lambda row: np.sqrt(row['mean_squared_error']) / row['scale'], axis=1)\n",
    "  return layer_stats\n",
    "  # layer_stats[['op_name', 'range', 'rmse/scale']].head()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 12:19:34.145411: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-28 12:19:35.249761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9650 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:8c:00.0, compute capability: 7.5\n",
      "2022-06-28 12:19:40.733680: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-06-28 12:19:40.733736: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-06-28 12:19:40.734538: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: ./checkpoints/day_tw_qat_tf29/save_model_0059_tflite/\n",
      "2022-06-28 12:19:40.772177: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2022-06-28 12:19:40.772234: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: ./checkpoints/day_tw_qat_tf29/save_model_0059_tflite/\n",
      "2022-06-28 12:19:40.881864: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-06-28 12:19:40.912799: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-06-28 12:19:41.393820: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: ./checkpoints/day_tw_qat_tf29/save_model_0059_tflite/\n",
      "2022-06-28 12:19:41.591819: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 857283 microseconds.\n",
      "2022-06-28 12:19:41.920991: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:40<00:00,  1.25it/s, image=datasets/data_selection/images/image_000741.jpg]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n",
      "  0%|                                                                                                                     | 0/50 [00:00<?, ?it/s, image=datasets/data_selection/images/image_002357.jpg]INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:04<00:00,  1.30s/it, image=datasets/data_selection/images/image_000741.jpg]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin model 6011416 bytes\n",
      "   op_name  tensor_idx  num_elements    stddev  mean_error  max_abs_error  \\\n",
      "0     RELU         118     2957312.0  0.006270   -0.002940       0.122591   \n",
      "1      PAD         122     2976800.0  0.000000    0.000000       0.000000   \n",
      "2  CONV_2D         126     1478656.0  0.173421    0.000573       0.929668   \n",
      "3     RELU         130     1478656.0  0.048481    0.006388       0.131863   \n",
      "4  CONV_2D         134     1478656.0  0.110942    0.000437       0.963905   \n",
      "\n",
      "   mean_squared_error     scale  zero_point  \\\n",
      "0            0.000050  0.247125        -128   \n",
      "1            0.000000  0.247125        -128   \n",
      "2            0.030075  0.600441          14   \n",
      "3            0.002393  0.266078        -128   \n",
      "4            0.012308  0.384223          27   \n",
      "\n",
      "                                         tensor_name  \n",
      "0                              model/tf.nn.relu/Relu  \n",
      "1                   model/quant_zero_padding2d_1/Pad  \n",
      "2  model/quant_batch_normalization_1/FusedBatchNo...  \n",
      "3                            model/tf.nn.relu_1/Relu  \n",
      "4  model/quant_batch_normalization_2/FusedBatchNo...  \n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.dirname(FLAGS.output)):\n",
    "  os.makedirs(os.path.dirname(FLAGS.output))\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(FLAGS.weights)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.allow_custom_ops = True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "  converter=converter, debug_dataset=representative_data_gen)\n",
    "debugger.run()\n",
    "\n",
    "\n",
    "origin_int8_model = debugger.get_nondebug_quantized_model()\n",
    "num_of_bytes = open('./origin_int8_model.tflite', 'wb').write(origin_int8_model)\n",
    "print(f'origin model {num_of_bytes} bytes')\n",
    "\n",
    "RESULTS_FILE = './debugger_results.csv'\n",
    "RESULTS_FILE_V2 = './debugger_results_V2.csv'\n",
    "with open(RESULTS_FILE, 'w') as f:\n",
    "  debugger.layer_statistics_dump(f)\n",
    "layer_stats = add_statistic(RESULTS_FILE)\n",
    "layer_stats.to_csv(RESULTS_FILE_V2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 14:52:31.275782: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-06-28 14:52:31.275845: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-06-28 14:52:31.276086: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: ./checkpoints/day_tw_qat_tf29/save_model_0059_tflite/\n",
      "2022-06-28 14:52:31.311694: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2022-06-28 14:52:31.311739: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: ./checkpoints/day_tw_qat_tf29/save_model_0059_tflite/\n",
      "2022-06-28 14:52:31.473567: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-06-28 14:52:32.023832: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: ./checkpoints/day_tw_qat_tf29/save_model_0059_tflite/\n",
      "2022-06-28 14:52:32.240056: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 963973 microseconds.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:41<00:00,  1.22it/s, image=datasets/data_selection/images/image_000741.jpg]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selective model 6037256 bytes. 15 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 14:53:19.468244: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file /home/user/anaconda3/envs/WJtf29/lib/python3.8/site-packages/tensorflow/lite/python/interpreter is not end with tflite_runtime/interpreter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 14:53:21.694088: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-28 14:53:22.539882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 508 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:8c:00.0, compute capability: 7.5\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Evaluating:   0%|                                                                                                                                                              | 0/1469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tflite\n",
      "./tflite_exp/selective_int8_model_rev_15layer_st81_end96.tflite\n",
      "CLASSES: {0: 'Green', 1: 'Red', 2: 'Yellow'}\n",
      "./datasets/data_selection_mix/anno/val_3cls.txt   #########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████| 1469/1469 [05:09<00:00,  4.75it/s, image_path=images_image_001786.jpg, correct_img=0.23(344/1469), recall_instance=0.49(1278/2630), accuracy_instance=0.42(1278/3039)]\n",
      "100%|██████████| 1469/1469 [00:00<00:00, 24663.98it/s]\n",
      "100%|██████████| 1469/1469 [00:00<00:00, 31192.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth yolo txt to coco json...\n",
      "Saving JSON file to mAP/tmpzrrfmlgh/ground-truth.json\n",
      "Predictions yolo txt to coco json...\n",
      "Saving JSON file to mAP/tmpzrrfmlgh/predicted.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.85s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
      "category : 0 : 0.084\n",
      "category : 1 : 0.126\n",
      "category : 2 : 0.081\n",
      "(all categories) mAP : 0.09710790000178256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.357\n",
      "category : 0 : 0.283\n",
      "category : 1 : 0.379\n",
      "category : 2 : 0.409\n",
      "(all categories) mAP : 0.35710257398861484\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.031\n",
      "category : 0 : 0.032\n",
      "category : 1 : 0.057\n",
      "category : 2 : 0.003\n",
      "(all categories) mAP : 0.03056553083363944\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= small | maxDets=100 ] = 0.128\n",
      "category : 0 : 0.096\n",
      "category : 1 : 0.126\n",
      "category : 2 : 0.160\n",
      "(all categories) mAP : 0.1275212615782888\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=medium | maxDets=100 ] = 0.183\n",
      "category : 0 : 0.118\n",
      "category : 1 : 0.145\n",
      "category : 2 : 0.286\n",
      "(all categories) mAP : 0.18312877753088394\n",
      " Average Precision  (AP) @[ IoU=0.50      | area= large | maxDets=100 ] = 0.744\n",
      "category : 0 : 0.683\n",
      "category : 1 : 0.782\n",
      "category : 2 : 0.766\n",
      "(all categories) mAP : 0.7436601749856435\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.081\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "# last_k=85\n",
    "st=81\n",
    "end=96\n",
    "for last_k in range(1):\n",
    "    suspected_layers = list(layer_stats['tensor_name'])[st:end]\n",
    "    debug_options = tf.lite.experimental.QuantizationDebugOptions(\n",
    "        denylisted_nodes=suspected_layers)\n",
    "    debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "        converter=converter,\n",
    "        debug_dataset=representative_data_gen,\n",
    "        debug_options=debug_options)\n",
    "\n",
    "    filename = f'./tflite_exp/selective_int8_model_rev_{len(suspected_layers)}layer_st{st}_end{end}.tflite'\n",
    "    selective_quantized_model_dbg = debugger.get_nondebug_quantized_model()\n",
    "    with open(filename, 'wb') as f:\n",
    "        num_of_bytes = f.write(selective_quantized_model_dbg)\n",
    "    f.close()\n",
    "    print(f'selective model {num_of_bytes} bytes. {len(suspected_layers)} layers')\n",
    "    subprocess.run(['python', 'evaluate_map_v3.py', '--weights', filename, '--framework', 'tflite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('WJtf29')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9de21d8ac59078702cddab91338c80379cc39134c659c0396b5010d46774626"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
